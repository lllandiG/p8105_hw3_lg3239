---
title: "p8105_hw3_lg3239"
author: "Landi Guo"
date: "2022-10-16"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
data("instacart")

instacart = 
  instacart %>% 
  as_tibble(instacart)
```

### Data Exploration

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, with each row resprenting a single product from an instacart order. Variables include identifiers for user, order, and product; the order in which each product was added to the cart. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. In total, there are `r instacart %>% select(product_id) %>% distinct %>% count` products found in `r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders from `r instacart %>% select(user_id) %>% distinct %>% count` distinct users.

There are 134 aisles, with fresh vegetables and fresh fruits holding the most items.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

This is a plot that shows the number of items ordered in each aisle, which is ordered by ascending number of items.

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```


This table shows the three most popular items in aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits`, including the number of times each item is ordered.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  #count the number of each product (n)
  count(product_name) %>% 
  #rank within each group according to n
  mutate(rank = min_rank(desc(n))) %>% 
  #three most popular items
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```
This is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

## Problem 2

### 1
The column names corresponding to each activity measurement are transformed to one variable `minute`, representing each minute of a 24-hour day starting at midnight. The values are transformed to `activity_measure`, representing the counts for each minute above. The type of `minute` is in numeric. An additional variable `weekday_vs_weekend` is added, specifying whether each measurement is on weekday or on weekend.

```{r}
acc_data = 
  read_csv("hw3_files/accel_data.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    starts_with("activity"),
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_measure"
  ) %>%
  mutate(minute = as.integer(minute)) %>%
  mutate(weekday_vs_weekend = if_else(day %in% c("Saturday", "Sunday"), "weekend", "weekday"
  )) %>%
  mutate(day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")))
```

This dataset contains `r nrow(acc_data)` rows and `r ncol(acc_data)` columns, with each row representing the observation of accelerometer data collected within one minute time frame. Variables include number of the week, number of the day, the day of the week, minute since midnight, accelerometer data, and whether on weekday or weekend. These correspond to `r names(acc_data)`. 

### 2

This table shows the total activity measurements for each day of the week. This table is intentionally in untidied format for readers. The maximum activity measurement are on the weekends for the first two weeks. In contrast, the maximum activity measurements are on weekdays for the following three weeks. The two lowest (abnormal) measurements happens on Saturday on the last two weeks with the value of 1440. The activity measurements are slightly higher on weekdays than on weekends.

```{r}
acc_data %>%
  group_by(week, day) %>%
  summarise(total_activity = sum(activity_measure)) %>%
  pivot_wider(
    names_from = "week",
    values_from = "total_activity"
  ) %>%
  knitr::kable(digits = 2)
```

### 3

This plot shows the 24-hour activity time courses for each day with different colors indicating day of the week. There are some obvious peaks for activity counts that are greater than 2500. The activity counts show remarkable increase or peaks approximately when in the morning around 8am, in the afternoon around 12pm, around 5pm, and in the evening around 9 pm. Most of the data are below 2500.

```{r}
acc_data %>%
  ggplot(aes(x = minute, y = activity_measure, group = interaction(week, day))) +
  geom_line(aes(color = day), alpha = .5) +
  labs(
    title = "24-hour activity time courses for each day",
    x = "Minute in a day",
    y = "Activity counts"
  ) 
```

## Problem 3

```{r}
data("ny_noaa")
```

This dataset contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns, with each row representing an observation on snow and weather conditions at certain weather station. Variables include `r names(ny_noaa)`, in which `prcp` is the precipitation in tenths of mm, `snow` is snowfall(mm), `snwd` is snow depth(mm), and `tmax` `tmin` are temperatures in tenths of degrees Celsius. The range of year is from 1981 to 2010. \
Each weather station may collect only a subset of these variables, resulting in extensive missing values in variables except `id` and `date`. Almost half of the `tmax` and `tmin` columns are missing, which could become a problem when analyzing data on these variables. There is no sufficient evidence that these missing values could be removed.\

### 1

For data cleaning, variables with units that are in tenths are converted to standard scale by dividing by 10. `month` variable is converted into month names, `day` and `year` are in numeric types.

```{r}
ny_noaa_tidy = 
  ny_noaa %>%
  mutate(tmax = as.numeric(tmax)/10) %>%
  mutate(tmin = as.numeric(tmin)/10) %>%
  mutate(prcp = prcp/10) %>%
  separate(date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = month.name[as.numeric(month)]) %>%
  mutate(day = as.numeric(day)) %>%
  mutate(year = as.numeric(year))

```

For snowfall, the most commonly observed value is `0` because there is no snow in most of the days in a year. Below is the code used to get the mode.

```{r}
# Create the function for mode
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

getmode(pull(ny_noaa_tidy, snow))
```

### 2

This plot shows the the average max temperature in January and in July in each station across years. Since there are too many weather stations, the distinctions between each station is not shown in the plot, and many of them overlap each other. The average max temperature in January ranges around -10 to 10 °C, with one obvious outlier in the early 80's. The average max temperature in July ranges around 20 to 33 °C, with an outlier below 15°C for a weather station in that specific year. 

```{r}
ny_noaa_tidy %>%
  group_by(id, year, month) %>%
  filter(month %in% c("January", "July")) %>%
  summarise(tmax_mean = mean(tmax, na.rm = TRUE)) %>%
  ggplot(aes(x = year, y = tmax_mean, group = id)) +
  geom_line(alpha = 0.5) +
  facet_grid(.~month) +
  labs(x = "Year",
       y = "Average maximum temperature (°C)",
       title = "Average max temperature in January and July for each station") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
  
```

### 3

This combined plot contains two plots: max vs. min temperature for all observations, and the distribution of snowfall values greater than 0 and less than 100 for each year.

```{r}
plot_i = 
  ny_noaa_tidy %>%
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex() +
  theme(legend.position = "right") +
  labs(x = "Minimum temperature (°C)",
       y = "Maximum temperature (°C)",
       title = "Max vs. min temperature for all observations") +
  theme(plot.title = element_text(size = 12))

plot_ii = 
  ny_noaa_tidy %>%
  filter(snow > 0 & snow < 100) %>%
  ggplot(aes(x = snow, y = year, group = year)) +
  geom_density_ridges(scale = 0.85) +
  labs(x = "Snowfall (mm)",
       y = "Year",
       title = "Distribution of snowfall (0 ~ 100mm) across years") +
  theme(plot.title = element_text(size = 12))
  
plot_i + plot_ii
```



